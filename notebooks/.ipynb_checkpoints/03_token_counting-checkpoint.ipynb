{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Token Counting & Cost Estimation\n",
    "\n",
    "This notebook installs `tiktoken` to estimate how many tokens our ReAct loop consumes.\n",
    "Since IBM Granite uses standard tokenizer architectures, `cl100k_base` (used by GPT-4) is a decent approximation for estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tiktoken --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from agent import get_agent_executor\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Initialize tokenizer\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def count_tokens(text):\n",
    "    return len(enc.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = get_agent_executor()\n",
    "query = \"How many letters are in 'Antidisestablishmentarianism'?\"\n",
    "\n",
    "print(f\"ðŸš€ Running query: {query}\")\n",
    "response = agent.invoke({\"messages\": [HumanMessage(content=query)]})\n",
    "\n",
    "total_input_tokens = 0\n",
    "total_output_tokens = 0\n",
    "\n",
    "print(\"\\nðŸ“Š Token Analysis per Step:\")\n",
    "for msg in response['messages']:\n",
    "    tokens = count_tokens(msg.content)\n",
    "    role = msg.type\n",
    "    print(f\"[{role.upper()}] Tokens: {tokens}\")\n",
    "    \n",
    "    if role == 'ai':\n",
    "        total_output_tokens += tokens\n",
    "    else:\n",
    "        total_input_tokens += tokens\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Total Input Tokens: {total_input_tokens}\")\n",
    "print(f\"Total Output Tokens: {total_output_tokens}\")\n",
    "print(f\"Estimated Total: {total_input_tokens + total_output_tokens}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}